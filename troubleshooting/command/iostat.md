**`iostat`** 的用法和常见参数示例（RHEL 8 中一般在 `sysstat` 包里）：

------

## 1. 安装

在 RHEL 8 上，`iostat` 属于 `sysstat` 工具集：

```
sudo dnf install -y sysstat
```

------

## 2. 基本用法

`iostat` 可以显示 CPU 使用率和磁盘 I/O 统计信息。
 命令格式：

```
iostat [参数] [间隔秒数] [重复次数]
```

例如：

```
iostat 2 5
```

👉 每隔 2 秒输出一次，总共输出 5 次。

------

## 3. 常见参数

### (1) **-x** ：扩展统计（推荐）

```
iostat -x 2 5
```

显示更详细的磁盘 I/O 信息，包括：

- `r/s, w/s`：每秒读写次数
- `rkB/s, wkB/s`：每秒读写 KB
- `await`：平均 I/O 等待时间（ms，越高说明磁盘性能瓶颈）
- `%util`：磁盘使用率（接近 100% 说明磁盘忙不过来）

------

### (2) **-d** ：只显示磁盘 I/O

```
iostat -d 2 5
```

只显示磁盘读写情况，不显示 CPU。

------

### (3) **-c** ：只显示 CPU

```
iostat -c 1 3
```

只显示 CPU 使用率。

------

### (4) **-m** ：以 MB 为单位显示

```
iostat -dxm 2 5
```

以 MB/s 为单位，扩展信息。

------

### (5) **-p** ：指定设备/分区

```
iostat -p sda 2 5
```

只查看 `sda` 磁盘的性能。

------

## 4. 输出解释（常见指标）

以 `iostat -x` 为例：

```
Device:   r/s   w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util
sda       5.0   2.0  40.0  10.0    20.0     0.1   5.2   0.4   35.0
```

- **r/s, w/s** ：每秒读写请求数
- **rkB/s, wkB/s** ：读写吞吐量（KB/s 或 MB/s）
- **avgrq-sz** ：平均每次 I/O 请求大小（扇区数）
- **avgqu-sz** ：平均队列长度（排队的 I/O 数量）
- **await** ：平均 I/O 等待时间（ms，>50ms 说明可能有瓶颈）
- **%util** ：磁盘利用率，接近 100% 时说明磁盘繁忙

------

## 5. 示例场景

- **定位磁盘瓶颈**：

```
iostat -x 1 10
```

看 `%util` 和 `await` 是否过高。

- **观察特定磁盘吞吐量**：

```
iostat -p sdb -mx 2 5
```





```
iostat -x 1
Linux 4.18.0-553.el8_10.x86_64 (localhost.localdomain) 	08/25/2025 	_x86_64_	(2 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           3.27    0.03    0.17    0.01    0.01   96.50

Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
vda              0.03    0.41      3.02    396.81     0.00     0.00   0.24   0.94    0.34   11.66   0.00   102.98   966.90   0.60   0.03
vdb              0.00    0.00      0.02      0.00     0.00     0.00   0.00   0.00    0.04    0.00   0.00    21.65     0.00   0.12   0.00
scd0             0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.04    0.00   0.00     3.14     0.00   0.29   0.00

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          47.76    0.00   26.87    0.50    1.00   23.88

Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
vda              0.99  836.63      7.92 833293.56     0.00     2.97   0.00   0.35    0.00   38.48  32.19     8.00   996.01   0.87  73.07
vdb              0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00
scd0             0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          52.26    0.00   37.19    0.00    1.01    9.55

Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
vda              0.00 1167.00      0.00 1163077.00     0.00     1.00   0.00   0.09    0.00   11.65  13.59     0.00   996.64   0.30  34.80
vdb              0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00
scd0             0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00


```



## 1️⃣ iostat -x 1 输出分析

### 第一段（空闲状态）

```
avg-cpu:  %user 3.27  %system 0.17  %iowait 0.01  %idle 96.50
vda: w/s=0.41, wkB/s=396.81, svctm=0.60, %util=0.03
```

- CPU 空闲 (`id=96.5%`)，磁盘几乎没压力 (`%util=0.03`)。
- 写入速度极低 (~396KB/s)，I/O 请求响应时间很短 (`svctm=0.6ms`)。
- 此时系统还未进行磁盘压测。

------

### 第二段（压力中）

```
avg-cpu: %user=47.76, %system=26.87, %iowait=0.50
vda: w/s=836.63, wkB/s=833293.56 KB/s, svctm=0.87ms, %util=73.07
```

- CPU 占用增加，系统态（`sy=26.87%`）也显著上升 → 表明磁盘 I/O 消耗了 CPU。
- 写速率非常高：约 **833 MB/s**。
- `%util=73%` → vda 设备约 3/4 时间被忙碌占用，说明 I/O 负载高。
- `w_await=38.48ms` → 磁盘请求平均等待时间 ~38ms，说明磁盘开始排队，但还在可接受范围。
- `rkB/s` 很小 → 压测主要是写操作。

------

### 第三段（压力高峰）

```
avg-cpu: %user=52.26, %system=37.19, %iowait=0
vda: w/s=1167, wkB/s=1163077 KB/s, svctm=0.30ms, %util=34.8
```

- 写速率进一步升高 (~1.1GB/s)，CPU 消耗增加。
- `%util=34.8%` 有点低，可能是因为 I/O 被缓存或批量写操作。
- `w_await=11.65ms` → 平均等待时间下降，可能数据写入被优化或使用了缓存。



```
    vmstat 1
    procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
     r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
     1  0      0 543940   3084 1118932    0    0     9  1782   81   57  3  0 96  0  0
     1  0      0 727704   3084 935200    0    0     0 626312 1492  288 33 19 37 10  1
     2  0      0 965640   3084 697324    0    0     0 911820 2109  255 49 30 21  1  0
     1  0      0 553768   3084 1109108    0    0     0 757816 1595  241 38 20 32 11  1
     1  0      0 807080   3084 855860    0    0     0 945225 2181  276 49 32 18  0  0
     1  0      0 568120   3084 1094756    0    0     0 856708 1370  240 28 15 32 25  1
     1  0      0 1052908   3084 610040    0    0     0 856520 2043  296 41 30 28  0  1
```



```
iostat -Ntkx 1 | tee -a $(hostname)-iostat.txt
```





```
device            r/s     w/s     rMB/s     wMB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
sdl              0.00    0.01      0.00      0.01     0.00     0.00  18.45   7.04    3.57   47.54   0.00   525.25   435.89  16.26   0.02
sdm              0.00    0.01      0.00      0.01     0.00     0.00   0.00   7.36    3.77   50.59   0.00   539.73   436.81  17.41   0.03
sdd              1.00   40.00      0.00     18.62     0.00     1.00   0.00   2.44    5.00    5.30   0.22     4.00   476.80   1.39   5.70
sdd              1.00   40.00      0.00     18.84     0.00     1.00   0.00   2.44    5.00   10.65   0.43     4.00   482.30   1.56   6.40
sdd              1.00   46.00      0.00     19.30     0.00     2.00   0.00   4.17    6.00    7.15   0.33     4.00   429.74   1.30   6.10
sdd              1.00   41.00      0.00     18.94     0.00     1.00   0.00   2.38    7.00    9.41   0.39     4.00   473.07   1.55   6.50
sdd              1.00   45.00      0.00     19.48     0.00     1.00   0.00   2.17    7.00    6.40   0.29     4.00   443.38   1.24   5.70
sdd              1.00   38.00      0.00     17.75     0.00     1.00   0.00   2.56    8.00    8.34   0.33     4.00   478.32   1.41   5.50
sdd              1.00   43.00      0.00     18.70     0.00     2.00   0.00   4.44    9.00    5.30   0.24     4.00   445.21   1.30   5.70
sdd              1.00   32.00      0.00     11.97     0.00     2.00   0.00   5.88   10.00    7.16   0.24     4.00   383.12   1.30   4.30

And we see the write await highest at 51.36ms:

Device            r/s     w/s     rMB/s     wMB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
sdh              0.00    0.02      0.00      0.01     0.00     0.00   0.80   6.58    1.01   40.15   0.00    23.57   408.42  13.72   0.02
sde              0.00    0.00      0.00      0.00     0.00     0.00   0.01  88.25    0.55   45.94   0.00    60.93    34.05   1.86   0.00
sdi              0.00    0.01      0.00      0.01     0.00     0.00   0.00   4.45    2.83   46.26   0.00   502.45   450.47  15.93   0.02
sdk              0.00    0.01      0.00      0.01     0.00     0.00   0.00   6.30    2.91   46.82   0.00   535.43   444.37  16.05   0.02
sdl              0.00    0.01      0.00      0.01     0.00     0.00  18.45   7.04    3.57   47.54   0.00   525.25   435.89  16.26   0.02
sdj              0.00    0.01      0.00      0.01     0.00     0.00  16.97   6.05    3.13   47.64   0.00   491.35   444.00  16.32   0.02
sdo              0.00    0.01      0.00      0.01     0.00     0.00   0.00   8.13    3.26   47.98   0.00   508.06   433.32  16.35   0.02
sdf              0.00    0.00      0.00      0.00     0.00     0.00   0.00  69.65    0.53   48.53   0.00    52.00    13.18   1.97   0.00
sdm              0.00    0.01      0.00      0.01     0.00     0.00   0.00   7.36    3.77   50.59   0.00   539.73   436.81  17.41   0.03
sdn              0.00    0.01      0.00      0.01     0.00     0.00   9.19   7.86    2.56   51.36   0.00   463.57   433.58  17.97   0.03

```



**Device**：设备名称（如 sdd, sde 等）。

**r/s**：每秒读请求数（IOPS）。

**w/s**：每秒写请求数（IOPS）。

**rMB/s**：每秒读的数据量（MB/s）。

**wMB/s**：每秒写的数据量（MB/s）。

**rrqm/s**：每秒合并的读请求数（Read merged）。

**wrqm/s**：每秒合并的写请求数（Write merged）。

**%rrqm**：读请求合并比例 = rrqm/s ÷ (r/s+rrqm/s)。

**%wrqm**：写请求合并比例 = wrqm/s ÷ (w/s+wrqm/s)。

**r_await**：平均读请求等待时间（ms）。

**w_await**：平均写请求等待时间（ms）。

**aqu-sz**：平均请求队列长度（IOs in queue）。

**rareq-sz**：平均每个读请求大小（KB）。



整理一个 **iostat 磁盘性能分析速查表**，结合常见的企业经验值，方便你快速定位磁盘 I/O 问题。

------

# 📌 iostat 磁盘性能分析速查表

| 指标                   | 含义                    | 正常范围（SSD/企业存储）                  | 正常范围（HDD） | 异常判断参考                                    |
| ---------------------- | ----------------------- | ----------------------------------------- | --------------- | ----------------------------------------------- |
| **r/s, w/s**           | 每秒读/写请求数（IOPS） | SSD 可达数千～数万                        | HDD 一般 < 200  | 突然飙高可能是应用异常或批量任务                |
| **rMB/s, wMB/s**       | 读/写吞吐量（MB/s）     | 取决于接口：SAS ≈ 600 MB/s, NVMe > 2 GB/s | HDD ≈ 100 MB/s  | 长时间接近硬件上限 → 带宽瓶颈                   |
| **r_await, w_await**   | 平均读/写请求延迟 (ms)  | SSD：0.1～1 ms 企业存储：< 5 ms           | HDD：5～20 ms   | > 20 ms 基本异常，> 50 ms 严重性能瓶颈          |
| **aqu-sz**             | 平均队列深度            | SSD < 1（正常）                           | HDD < 1（正常） | > 2 表示 I/O 堆积，> 10 严重拥塞                |
| **rareq-sz, wareq-sz** | 平均请求大小 (KB)       | 随机 I/O：≈ 4–16 KB 顺序 I/O：> 128 KB    | 类似            | 突然变小 → 应用变成随机访问；过大可能是批量任务 |
| **svctm**              | 平均服务时间 (ms)       | SSD < 1 ms                                | HDD ≈ 5–15 ms   | > 20 ms 说明设备服务不过来                      |
| **%util**              | 磁盘利用率              | < 70%（健康）                             | < 70%（健康）   | > 80% 长期高负载；≈100% 表示设备满负荷          |

------

## 📊 快速判断逻辑

1. **先看 %util**

   - < 70% → 正常

   - > 80% → 磁盘可能在瓶颈

   - 100% → 单盘跑满，可能需要扩容或调优

2. **再看 r_await / w_await**

   - SSD 正常 < 1ms
   - HDD 正常 < 20ms
   - 超过阈值说明 I/O 延迟大

3. **对比 aqu-sz**

   - 队列深度 > 2 表示请求堆积
   - 队列深度高 + 延迟高 = **I/O 拥塞**

4. **结合请求大小 rareq-sz/wareq-sz**

   - 如果请求突然变小（4K 左右），说明变成随机 I/O，性能会急剧下降。
   - 如果大部分是大 I/O，吞吐量就要接近带宽上限。

------

## 🚨 常见问题场景

- **高延迟 + 高 util** → 设备性能不足 / 存储压力过大
- **高延迟 + util 不高** → 应用程序锁等待 / RAID 控制器瓶颈
- **aqu-sz 高** → I/O 堆积，队列满
- **读写请求大小异常** → 应用负载模式突变
